---
title: "Data Import and Wrangling"
output: html_notebook
---


### What is R and RStudio? 

R is an open-source statistical programming language that is growing very fast in the world of data science. 

To download R, go to: 

https://cloud.r-project.org

and then click on the link for either Mac, Windows or Linux depending on your computer. 

To install RStudio, go to: 

http://www.rstudio.com/download

RStudio is an integrated development environment (or IDE) for R programming. It makes writing and running R code more fun. 

for more info, have a look at this section from *R for Data Science*: 

http://r4ds.had.co.nz/introduction.html#prerequisites


### Packages

R the programming language consists of base R and the packages that have been built on top of it. Once you have downloaded base R onto your computer and installed RStudio, you need to install the packages we will be using for this workshop.

To install a package on your computer, run `install.packages("name of package")`. To use that package, place `library(name of package)` at the top of your R script or R Markdown file and run it.


### R Markdown

The file we are looking at and using today is called an `R Markdown` file. It's a file format that let's us interweave code chunks that look like this: I can write whatever. 

```{r}
mtcars
```

Along with plain text prose, which is what we are reading right now. We can then `knit` this to a PDF, an HTML file or a Notebook. We could have used an R script, which would have the file extension `.R`. Click `file` -> `New File` -> `R Script` to open an R script. Click `file` -> `New File` -> `R Notebook` to open an Rmarkdown Notebook.



### Load the packages

All my R Notebooks start with this step. We need our tools! 

If you are using R for the first time on this computer, you'll need to install all these packages to your machine.

```{r setup, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = NA)

# install.packages(dplyr) 
# install.packages(tidyr)
# install.packages(readr)
# install.packages(readxl)
# install.packages(janitor)

library(dplyr) 
library(tidyr)
library(readr)
library(readxl)
library(janitor)
```


What we will cover today:

    + import an Excel spreadsheet
    + import a csv file
    + Remove rows with slice()
    + Pick columns by their names select()
    + Pick observations by their values filter()
    + Create new variables with functions of existing variables mutate()
    + Reorder the rows arrange()
    + rename columns with rename()
    + summarise values with summarise()
    + pull apart dates with separate()
    + Pivot data from wide to long, tidy format with pivot_longer() 
    + group_by() changes the scope to operating group-by-group
    + Hadley reckons this covers about 90% of data wrangling in tidyverse
    
Link to book R for Data Science
https://r4ds.had.co.nz/

Link to tidyverse
https://www.tidyverse.org/packages/

Link to more code and Shiny apps related to finance

http://www.reproduciblefinance.com/

# Import Data

How, why, where did it come from? 

https://www.fhfa.gov/DataTools/Downloads/Pages/House-Price-Index-Datasets.aspx

Often this will involve grabbing data from internal databases, or from a repository set up by a vendor, or from someone emailing us excel and csv files.

For today, we will import one local Excel file, one local CSV file and one internet file.

Before getting to code, click on the file and notice how to use the `Import Dataset` button at the top right. This can be a huge time saver and it generates code for us!

Always, always, paste the full code into the script. Future you will thank past you.


### From local Excel file

```{r, eval = FALSE}
# library(readxl)

hpi_from_excel <- read_excel("path to your local excel file")


```

### From local csv file: two ways

We can use `read_csv()` from `readr`.

```{r, eval = FALSE}
# library(readr)

hpi_from_csv <- read_csv("path to your local csv file")


```

### From the internet

From the internet or from local file, either way, RStudio needs a path to the excel or csv.

```{r}
# library(readxl)

url <- "https://www.fhfa.gov/DataTools/Downloads/Documents/HPI/HPI_PO_monthly_hist.xls"

destfile <- "hpi.xls"

curl::curl_download(url, destfile)

hpi <- read_excel(destfile, skip = 3)


```

Quick glance at the data

```{r}
head(hpi)

hpi %>% 
  head() 
  

hpi %>% 
  View()
```


### Data frames and tibbles

```{r}
hpi %>% 
  class() 
```

what is  a `tibble`? It's really just a data frame. People use these interchangeably.


### What's that weird `%>%`?

This is called the 'pipe' operator. It chains together our functions so we don't have to create new objects each time we do something. It will appear dozens of times today and by the end you'll be tired of seeing it. We can think of this as reading `and then`, it tells the code to keep processing and moving to the next function. 

We think it makes code more readable and logical, and it saves us from having to create new variable at each line.


### Wrangle data

Key packages are `dplyr` and `tidyr`, both part of the tidyverse! 

We have our data object. Let's: 

1. use `clean_names()` from `janitor` package to clean up column names
2. use `slice()` from `dplyr` to delete or keep or select rows
3. use `filter()` from `dplyr`to select by row values
4. use `select()` from `dplyr` to delete and choose columns
5. use `mutate()` from `dplyr` to create new columns
6. use `rename()` from `dplyr` for column renaming
7. use `summarise()` from `dplyr` for calculating across rows
8. use `separate()` from `tidyr` for splitting columns
9. use `unite()` from `tidyr` for combining columns
10. use `case_when()` to add labels, and `between` as a short cut for x >= & x <=
11. use `separate()` and `unite` to split and combine columns


```{r}
hpi %>% 
  # clean_names() from janitor package to clean up column names
  clean_names() %>% 
  # slice() from dplyr to remove the first (empty) row
  slice(-1) %>% 
  # filter() from dplyr to choose data from 2000 on
  filter(month >= as.Date("2000-01-01")) %>% 
  # select() from dplyr to pick columns
  select(month, middle_atlantic_sa) %>% 
  # mutate() from dplyr to create new columns based on other columns
  mutate(middle_atlantic_times_2 = middle_atlantic_sa *2) %>% 
  # rename() from dplyr to rename columns
  rename(better_name = middle_atlantic_times_2) %>% 
  # summarise() from dplyr to summarize across rows
  summarise(mean_of_middle_atlantic = mean(middle_atlantic_sa))
```


```{r}
hpi_wrangled <- hpi %>% 
  clean_names() %>% 
  slice(-1) %>%   # remove empty row
  rename(date = month) %>%
  select(date, ends_with("_sa")) %>%  # only keep seasonally adj. data
  # separate() from tidyr package to split date into separate columns for day/month/year 
  separate(date, into = c("year", "month", "day"), sep = '-', convert = TRUE, remove = FALSE) %>% 
  # unite() from tidyr to join columns 
  unite(yr_mon, year, month, sep = "/", remove = FALSE) %>% 
  mutate_if(is.numeric, round, digits = 2) %>%  # round all numeric columns to 2 digits
  # add labels with case_when()
  mutate(season = case_when(between(month, 3, 5) ~ "spring",
                            between(month, 6, 8) ~ "summer",
                            between(month, 9, 11) ~ "fall",
                            # between(month, 12, 2) ~ "winter" == won't work because there's no numbers between 12 and 2
                            TRUE ~ "winter")) %>% 
  # arrange() from dplyr to sort rows
  arrange(date)
  
hpi_wrangled %>%
  tail(10)

```

### Tidy Data

What is tidy data?

https://tidyr.tidyverse.org/

    + Each variable is in a column.
    + Each observation is a row.
    + Each value is a cell.

simple definition == took Hadley two years!!
    
http://r4ds.had.co.nz/tidy-data.html

Converting from wide to tidy is not intuitive. It takes practice and trial/error (at least, it took me a lot of practice and trial/error).

1. use `pivot_longer()` from `tidyr` to make into long data
2. `pivot_wider()` does the opposite
3. Long data is easier for computers, wide is easier for humans
4. Allows us to `group_by()` and scale our operations

```{r}
hpi_tidy <- 
  hpi_wrangled %>% 
  select(date, contains("north"), contains("south")) %>% 
  # pivot_longer makes data long, or tidy
  pivot_longer(-date, names_to = "division", values_to = "hpi") %>% 
  group_by(division)

hpi_untidied <- 
  hpi_tidy %>% 
  # pivot_wider makes data wide, or untidy
  pivot_wider(names_from = "division", values_from = "hpi")
```

Why is tidy data so useful?

Adding multiple columns. How would we do this with wide date? slowly and painfully

```{r}
hpi_tidy %>% 
  mutate(pct_change = (hpi / lag(hpi)) - 1,  # lag from dplyr to refer to previous value
         pct_change_12_mons = (hpi / lag(hpi, 12)) - 1,
         pct_change_24_mons = (hpi / lag(hpi, 24)) - 1) %>% 
  # See what happens if you remove the na.omit() line
  na.omit()
```

Notice how `mutate()` respects our `group_by`. The data frame is aware of our discrete groups.

### Summarize data

Calculating summary stats much more efficient with tidy data

```{r}
hpi_tidy %>% 
  mutate(pct_change = (hpi / lag(hpi)) - 1) %>%
  na.omit() %>% 
  summarise(mean_pct_change = mean(pct_change),
            sd_pct_change = sd(pct_change),
            min_pct_change = min(pct_change))
```

We can add labels and count percentages by groups.

```{r}
hpi_tidy %>% 
  group_by(division) %>% 
  mutate(pct_change = (hpi / lag(hpi)) - 1) %>%
  na.omit() %>%
  mutate(change_label = case_when(pct_change > 0  ~ "positive",
                                  pct_change <= 0  ~ "negative"
                                  )) %>% 
  count(change_label) %>% 
  mutate(percent = n/sum(n))
```


And finally a preview for next week: 
```{r}
library(ggplot2)

ggplot(hpi_tidy, aes(x = date, y = hpi, color = division)) +
         geom_line()
```

